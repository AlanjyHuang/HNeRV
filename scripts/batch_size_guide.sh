#!/bin/bash
# Quick batch size recommendations based on GPU memory

echo "=========================================="
echo "Batch Size Recommendations"
echo "=========================================="
echo ""
echo "Your GPU: 40960 MiB (40 GB)"
echo ""
echo "Based on your model configurations:"
echo ""
echo "1. SMALL MODEL (fc_dim=128, fc_hw=5_8):"
echo "   • Model size: ~7M parameters"
echo "   • Memory per sample: ~150-200 MB"
echo "   • Recommended batch_size: 16-32"
echo "   • Safe starting point: 16"
echo ""
echo "2. MEDIUM MODEL (fc_dim=256, fc_hw=9_16):"
echo "   • Model size: ~30M parameters"  
echo "   • Memory per sample: ~400-600 MB"
echo "   • Recommended batch_size: 8-16"
echo "   • Safe starting point: 8"
echo ""
echo "3. LARGE MODEL (fc_dim=512, fc_hw=9_16):"
echo "   • Model size: ~105M parameters"
echo "   • Memory per sample: ~1000-1500 MB"
echo "   • This will OOM on your GPU!"
echo "   • Don't use this configuration"
echo ""
echo "=========================================="
echo "Quick Test Commands:"
echo "=========================================="
echo ""
echo "# Test small model with batch_size=16"
echo "CUDA_VISIBLE_DEVICES=7 python train_patch_dual.py \\"
echo "    --data_path data/Kitchen \\"
echo "    --vid Kitchen \\"
echo "    --fc_dim 128 \\"
echo "    --fc_hw 5_8 \\"
echo "    --batchSize 16 \\"
echo "    --epochs 1 \\"
echo "    --data_split 8_9_10 \\"
echo "    --debug"
echo ""
echo "# Test medium model with batch_size=8"
echo "CUDA_VISIBLE_DEVICES=7 python train_patch_dual.py \\"
echo "    --data_path data/Kitchen \\"
echo "    --vid Kitchen \\"
echo "    --fc_dim 256 \\"
echo "    --fc_hw 9_16 \\"
echo "    --dec_strds 5 3 2 2 2 \\"
echo "    --batchSize 8 \\"
echo "    --epochs 1 \\"
echo "    --data_split 8_9_10 \\"
echo "    --debug"
echo ""
echo "If these work, you can gradually increase batch size!"
echo ""
